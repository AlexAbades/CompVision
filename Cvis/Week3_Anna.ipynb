{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb122e6",
   "metadata": {},
   "source": [
    "## Exercise 3: Stereo vision, and triangulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588fc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dae0114",
   "metadata": {},
   "source": [
    "### Epipolar geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7624d0",
   "metadata": {},
   "source": [
    "Set up two cameras, both with the internal parameters:\n",
    "\n",
    "$$ K = \\begin{bmatrix} 1000 & 0 & 300 \\\\ 0 & 1000 & 200 \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "Now, for the first camera — let us call that `Cam` — set the rotation to identity $R_1 = I$ and set the translation to zero $t_1 = 0$. For the second camera `Cam` use the rotation given by the R function: $R_2= R(0.7,−0.5,0.8)$.\n",
    "\n",
    "\n",
    "$$ R(\\theta_x,\\theta_y,\\theta_z) = \\begin{bmatrix} cos(\\theta_z) & -sin(\\theta_z) & 0 \\\\ sin(\\theta_z) & cos(\\theta_z) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} cos(\\theta_y) & 0 & -sin(\\theta_y)\\\\ 0 & 1 & 0 \\\\ sin(\\theta_y) & 0 & cos(\\theta_y) \\end{bmatrix} \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & cos(\\theta_x) & -sin(\\theta_x) \\\\ 0 & sin(\\theta_x) & cos(\\theta_x) \\end{bmatrix}$$\n",
    "\n",
    "and the translation:\n",
    "$$ t_2 = \\begin{bmatrix} 0.2 \\\\ 2 \\\\ 1 \\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91d9e6",
   "metadata": {},
   "source": [
    "- **Exercise 3.1**. Consider the 3D point:\n",
    "$$ Q = \\begin{bmatrix} 1 \\\\ 0.5 \\\\ 4 \\\\ 1 \\end{bmatrix}$$\n",
    "and find the projections in `Cam` and `Cam2` respectively, points $q_1$ and $q_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742853ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=np.array([[1000,0,300],[0,1000,200],[0,0,1]])\n",
    "\n",
    "R1=np.eye(3)\n",
    "t1=np.zeros((3,1))\n",
    "Cam1=np.column_stack((R1,t1))\n",
    "\n",
    "R2=Rotation.from_euler('xyz', [0.7, -0.5, 0.8]).as_matrix()\n",
    "t2=np.array([[0.2],[2],[1]])\n",
    "Cam2=np.column_stack((R2,t2))\n",
    "\n",
    "Q=[1,0.5,4,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64f5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectpoints(K,Cam,Q):\n",
    "    #projection matrix P\n",
    "    P=K@Cam\n",
    "    \n",
    "    Q_ext=np.transpose(Q)\n",
    "    projection=P@Q_ext\n",
    "    \n",
    "    qx=np.transpose([projection[0]/projection[2]])\n",
    "    qy=np.transpose([projection[1]/projection[2]])\n",
    "    \n",
    "    project2D=np.column_stack((qx,qy))\n",
    "    \n",
    "    project3D=np.transpose(projection)\n",
    "    \n",
    "    return project2D,project3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23172a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection of point Q in first camera is p1= [550. 325.]\n",
      "The projection of point Q in first camera is p2= [582.47256835 185.98985776]\n"
     ]
    }
   ],
   "source": [
    "p1,p1_3D=projectpoints(K,Cam1,Q)\n",
    "print('The projection of point Q in first camera is p1=',p1[0])\n",
    "\n",
    "p2,p2_3D=projectpoints(K,Cam2,Q)\n",
    "print('The projection of point Q in first camera is p2=',p2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc4cf5",
   "metadata": {},
   "source": [
    "- **Exercise 3.2**. Implement a function `CrossOp` that takes a vector in 3D and returns the 3×3 matrix corresponding to taking the cross product with that vector. In the case that $p = [x  y  z]^T$ you should have:\n",
    "\n",
    "$$ CrossOp(p) = [p]_x = \\begin{bmatrix} 0 & -z & y \\\\ z & 0 & -x \\\\ -y & x & 0  \\end{bmatrix}$$\n",
    "\n",
    "As a good habit, verify that your function works by testing it on random vectors to ensure that:\n",
    "$$ [p_1]_x p_2 = p_1 x p_2 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed15da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossOp(p):\n",
    "    x,y,z=p[0],p[1],p[2]\n",
    "    cross=np.array([[0,-z,y],[z, 0,-x],[-y,x,0]])\n",
    "    return cross"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ada9c",
   "metadata": {},
   "source": [
    "- **Exercise 3.3**. Compute the **fundamental matrix F** of the two cameras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1051a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Fmat_Emat(t,R,K1,K2):\n",
    "    #K1, K2 instrincisc properties of each camera. \n",
    "    \n",
    "    t_cross=CrossOp(t[:,0])\n",
    "    E=t_cross@R2 #essential matrix\n",
    "\n",
    "    F=np.linalg.inv(K2).T@E@np.linalg.inv(K1)\n",
    "    return E, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274386a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The essential matrix is E =\n",
      "[[ 0.32931188  0.81939633  2.05429875]\n",
      " [ 0.51553255 -0.87691598  0.07241923]\n",
      " [-1.09692748  1.5899527  -0.55569822]]\n",
      "\n",
      "The fundamental matrix is F =\n",
      "[[ 3.29311881e-07  8.19396327e-07  1.79162592e-03]\n",
      " [ 5.15532551e-07 -8.76915984e-07  9.31426656e-05]\n",
      " [-1.29882755e-03  1.51951700e-03 -1.10072682e+00]]\n"
     ]
    }
   ],
   "source": [
    "E,F= compute_Fmat_Emat(t2,R2,K,K)\n",
    "print('The essential matrix is E =')\n",
    "print(E)\n",
    "print(\"\")\n",
    "print('The fundamental matrix is F =')\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e7e45",
   "metadata": {},
   "source": [
    "- **Exercise 3.4**. What is the epipolar line _l_ of _$q_1$_ in camera two?\n",
    "\n",
    "<font color='darkblue'> We can compute the epipolar lines l = Fp from just the Fundamental matrix and the corresponding points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f5b5d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The epipilar line l of q_1 in camera 2 is: [ 8.95620504e-03  3.66751496e-04 -5.28495581e+00]\n"
     ]
    }
   ],
   "source": [
    "l= F@p1_3D\n",
    "\n",
    "print('The epipilar line l of q_1 in camera 2 is:',l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57cfa7",
   "metadata": {},
   "source": [
    "- **Exercise 3.5**. Is $q_2$ located on the epipolar line from Ex. 3.4? Do the computations, but also explain why this must be so.\n",
    "\n",
    "<font color='darkblue'> To see if a point _q_ is on a line we can use that $q^T l = 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b806e954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of q2l is: 7.105427357601002e-15\n",
      "Takinh numerical precision into account, the approximation is 0 .\n",
      "Then, the point is on the line.\n"
     ]
    }
   ],
   "source": [
    "p_on_l=p2_3D.T@l\n",
    "print('The result of q2l is:',p_on_l)\n",
    "print('Takinh numerical precision into account, the approximation is',round(p_on_l),'.')\n",
    "print('Then, the point is on the line.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09556c08",
   "metadata": {},
   "source": [
    "<font color='darkblue'> This must be true, since both the point $q_2$ and the line $l$ are derived from the same 3D point $Q$. This 3D point yields a single epipolar plane, and the plane yields a single line in each camera. The projections of the 3D point must lie on the epipolar lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a43248",
   "metadata": {},
   "source": [
    "- **Exercise 3.6**. Now assume that both camera one and two have local coordinate systems that are different from the coordinate system of the world.\n",
    "\n",
    "Let $Q$ and $Q'$ denote the same 3D point in world space and in the frame of camera one. In other words we have relation:\n",
    "\n",
    "$$ Q' = \\begin{bmatrix} R_1 & t_1 \\\\ 0 & 1 \\end{bmatrix} Q $$\n",
    "\n",
    "Make sure you understand why this is true. Show analytically that\n",
    "$$ Q = \\begin{bmatrix} R_1^T & -R_1^T t_1 \\\\ 0 & 1 \\end{bmatrix} Q' $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384343e",
   "metadata": {},
   "source": [
    "<font color='darkblue'> \n",
    "    \n",
    "$$ Q' = \\begin{bmatrix} R_1 & t_1 \\\\ 0 & 1 \\end{bmatrix}  \\begin{bmatrix} R_1^T & -R_1^T t_1 \\\\ 0 & 1 \\end{bmatrix} Q'$$\n",
    "    \n",
    "    \n",
    "$$ Q' = \\begin{bmatrix} R_1 R_1^T & -R_1R_1^T+t_1 \\\\ 0 & 1 \\end{bmatrix}Q'$$\n",
    "    \n",
    "$$ Q' = \\begin{bmatrix} I & 0 \\\\ 0 & 1 \\end{bmatrix}Q'$$\n",
    "    \n",
    "And we find that it is valid! This is true as the matrices are inverses of each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26995545",
   "metadata": {},
   "source": [
    "<font color='darkblue'> \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9369c",
   "metadata": {},
   "source": [
    "- **Exercise 3.7**. Show that the can work only in the coordinate system of camera one, by showing that we can project points with\n",
    "\n",
    "\n",
    "$$ q_1 = K \\begin{bmatrix} I & 0 \\end{bmatrix} Q' ,   q_2 = K \\begin{bmatrix} R_2' & t_2' \\end{bmatrix} Q'$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ R_2' = R_2 R_1^T, t_2'= t_2 - R_2 R_1^T t_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbde93",
   "metadata": {},
   "source": [
    "<font color='darkblue'> For the first projection in camera one we reduce the projection equation: \n",
    "\n",
    "<font color='darkblue'>\n",
    "$$ q_1 = K\\begin{bmatrix} R_1| & t_1 \\end{bmatrix} Q, $$ \n",
    "$$ = K \\begin{bmatrix} I & 0 \\end{bmatrix} \\begin{bmatrix} R_1 & t_1\\\\ 0 & 1 \\end{bmatrix}Q , $$\n",
    "    \n",
    "$$ = K \\begin{bmatrix} I & 0 \\end{bmatrix} Q' , $$\n",
    "\n",
    "    \n",
    "<font color='darkblue'> For the second projection into camera two we insert: \n",
    "\n",
    "<font color='darkblue'>\n",
    "$$ q_2 = K\\begin{bmatrix} R_2|& t_2 \\end{bmatrix} Q, $$ \n",
    "$$ q_2 = K \\begin{bmatrix} R_2|& t_2 \\end{bmatrix} \\begin{bmatrix} R_1 & t_1\\\\ 0 & 1 \\end{bmatrix} Q' , $$\n",
    "$$ q_2 = K \\begin{bmatrix} R_2 R_1^T & t_2-R_2't_1 \\end{bmatrix} Q' , $$\n",
    "$$ q_2 = K \\begin{bmatrix} R_2' & t_2' \\end{bmatrix} Q' . $$\n",
    "    \n",
    "where $$ R_2'= R_2R_1^T , t_2' = t_2 - R_2't_1  $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6a140",
   "metadata": {},
   "source": [
    "### Applied Epipolar geometry\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa7ff12",
   "metadata": {},
   "source": [
    "- **Exercise 3.8**. Load the file TwoImageData.npy, and compute the fundamental matrix between camera one and two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f12e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 is the identity matrix and t1 is 0.\n",
      " \n",
      "The fundamental matrix is F =\n",
      "[[ 0.00000000e+00 -2.22112237e-06 -3.98073573e-05]\n",
      " [ 2.22146629e-06  0.00000000e+00  9.89719467e-06]\n",
      " [-2.01415021e-04 -6.43129930e-02 -1.15352646e+00]]\n"
     ]
    }
   ],
   "source": [
    "data= np.load('TwoImageData.npy', allow_pickle=True).item()\n",
    "print('R1 is the identity matrix and t1 is 0.')\n",
    "t2=data['t2']\n",
    "R2=data['R2']\n",
    "R2=data['K']\n",
    "E,F= compute_Fmat_Emat(t2,R2,K,K)\n",
    "print(\" \")\n",
    "print('The fundamental matrix is F =')\n",
    "print(F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a95f2a",
   "metadata": {},
   "source": [
    "- **Exercise 3.9**. Write code that can show both images at the same time. Now write code such that you can click on a point in image one, and display the corresponding epipolar line in image two. Experiment with your code, verifying that the point you click on is on the epipolar line in the other image.\n",
    "\n",
    "To click on a point and get the pixel coordinates you can use `plt.ginput(1)`.\n",
    "To draw a line given in homogeneous coordinates, you can use the `DrawLine` function below. It takes as input a line in homogeneous coordinates l and the size of the image it will be drawn on, as returned by im.shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading images\n",
    "img1=data['im1']\n",
    "img2=data['im2']\n",
    "\n",
    "# concatanate image Horizontally\n",
    "Hori = np.concatenate((img1, img2), axis=1)\n",
    "shape_img=Hori.shape\n",
    "\n",
    "#cv2.imshow('HORIZONTAL', Hori)\n",
    "# wait for a key to be pressed to exit\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# close the window\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#To click on a point and get the pixel coordinates\n",
    "#x = plt.ginput(1)\n",
    "#print(x)\n",
    "\n",
    "\n",
    "#Compute the epipolar line in image two\n",
    "#epi_l= F@p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c31d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawLine(l, shape):\n",
    "    #Checks where the line intersects the four sides of the image\n",
    "    # and finds the two intersections that are within the frame\n",
    "    def in_frame(l_im):\n",
    "        q = np.cross(l.flatten(), l_im)\n",
    "        q = q[:2]/q[2]\n",
    "        if all(q>=0) and all(q+1<=shape[1::-1]):\n",
    "            return q\n",
    "    lines = [[1, 0, 0], [0, 1, 0], [1, 0, 1-shape[1]], [0, 1, 1-shape[0]]]\n",
    "    P = [in_frame(l_im) for l_im in lines if in_frame(l_im) is not None]\n",
    "    plt.plot(*np.array(P).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display= DrawLine(epi_l, shape_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035af36",
   "metadata": {},
   "source": [
    "- **Exercise 3.10**. Do the same thing as the last exercise, but where you can click in image two and get the epipolar line displayed in image one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ddaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "617c069a",
   "metadata": {},
   "source": [
    "### Programming exercise: Triangulation\n",
    "\n",
    "- **Exercise 3.11**. Create a function `triangulate` that takes a list of pixel coordinates (q1, q2, . . . , qn), and a list of projection matrices (P1, P2, . . . , Pn), and the function returns the triangulation of the point using the linear algorithm.\n",
    "\n",
    "\n",
    "Test your function by defining some 3D points — use the box3D function, for example — project them to the image planes of the two cameras, and then re-triangulate them back to the original coordinates.\n",
    "\n",
    "You can similarly use a number of corresponding pixel coordinates, triangulate them, and then re-project the 3D points into the cameras. Do you find the same 2D pixels? If not, why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "095ba6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate(pixel_coord, proj_mat):\n",
    "    B=np.zeros((1,2))\n",
    "    for ind, a in enumerate(pixel_coord):\n",
    "        for aa in a:\n",
    "            if aa[2] != 0 :\n",
    "                x=aa[0]/aa[2]\n",
    "                y=aa[1]/aa[2]\n",
    "                B_i=np.array([proj_mat[ind][2][:-1]*x - proj_mat[ind][0][:-1]],[proj_mat[ind][2][:-1]*y - proj_mat[ind][1][:-1]])\n",
    "    \n",
    "    \n",
    "    B=np.vstack([B, B_i])\n",
    "    B=B[1:,:] \n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1f088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box3d(n):\n",
    "    comb=[(0.5,0.5),(0.5,-0.5),(-0.5,0.5),(-0.5,-0.5)]\n",
    "    a=np.linspace(-0.5, 0.5, n)\n",
    "    box=[0,0,0]\n",
    "\n",
    "    for j in comb:\n",
    "        for i in a:\n",
    "            p=[i,j[0],j[1]]\n",
    "            box=np.vstack([box, p])\n",
    "\n",
    "    for j in comb:\n",
    "        for i in a[1:-1]:\n",
    "            p=[j[0],i,j[1]]\n",
    "            box=np.vstack([box, p])\n",
    "\n",
    "    for j in comb:\n",
    "        for i in a[1:-1]:\n",
    "            p=[j[0],j[1],i]\n",
    "            box=np.vstack([box, p])\n",
    "\n",
    "    for i in a:\n",
    "        cross1=[i,0,0]   \n",
    "        box=np.vstack([box, cross1])\n",
    "    for i in a:\n",
    "        cross2=[0,i,0]   \n",
    "        box=np.vstack([box, cross2])\n",
    "    for i in a:\n",
    "        cross3=[0,0,i]   \n",
    "        box=np.vstack([box, cross3])\n",
    "      \n",
    "    box=box[1:]\n",
    "    \n",
    "\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b86c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord=box3d(16)\n",
    "[m,n]=np.shape(coord)\n",
    "cnt=np.ones(m)\n",
    "Q_ext=np.column_stack((coord,cnt)).T\n",
    "    \n",
    "P1=K@Cam1\n",
    "P2=K@Cam2\n",
    "\n",
    "#We project the 3D points to the image planes of the two cameras\n",
    "projection1=(P1@Q_ext).T\n",
    "projection2=(P2@Q_ext).T\n",
    "\n",
    "#Then, we re-triangulate them back to the original coordinates.\n",
    "pixel_coord=[projection1,projection2]\n",
    "proj_mat=[P1,P2]\n",
    "#tri_Q= triangulate(pixel_coord, proj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736e0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2063011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2779110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
